{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola **Alek**!\n",
    "\n",
    "Soy **Patricio Requena** üëã. Es un placer ser el revisor de tu proyecto el d√≠a de hoy!\n",
    "\n",
    "Revisar√© tu proyecto detenidamente con el objetivo de ayudarte a mejorar y perfeccionar tus habilidades. Durante mi revisi√≥n, identificar√© √°reas donde puedas hacer mejoras en tu c√≥digo, se√±alando espec√≠ficamente qu√© y c√≥mo podr√≠as ajustar para optimizar el rendimiento y la claridad de tu proyecto. Adem√°s, es importante para m√≠ destacar los aspectos que has manejado excepcionalmente bien. Reconocer tus fortalezas te ayudar√° a entender qu√© t√©cnicas y m√©todos est√°n funcionando a tu favor y c√≥mo puedes aplicarlos en futuras tareas. \n",
    "\n",
    "_**Recuerda que al final de este notebook encontrar√°s un comentario general de mi parte**_, empecemos!\n",
    "\n",
    "Encontrar√°s mis comentarios dentro de cajas verdes, amarillas o rojas, ‚ö†Ô∏è **por favor, no muevas, modifiques o borres mis comentarios** ‚ö†Ô∏è:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si todo est√° perfecto.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si tu c√≥digo est√° bien pero se puede mejorar o hay alg√∫n detalle que le hace falta.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si de pronto hace falta algo o existe alg√∫n problema con tu c√≥digo o conclusiones.\n",
    "</div>\n",
    "\n",
    "Puedes responderme de esta forma:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta del estudiante</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "**Tip**: Para mejorar la presentaci√≥n de tus notebooks es recomendable dejar siempre en la primera celda un t√≠tulo y una breve introducci√≥n al proyecto para que sea claro desde el inicio lo que se realizar√°\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as a utilizar y m√≥dulos de sklearn:\n",
    "import pandas as pd # manipulaci√≥n de datos\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor # √Årboles de decisi√≥n\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression # no necesaria para la tarea, se trata de una clasificaci√≥n(?) se usar√° regresi√≥n log√≠stica\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor # Bosque Aleatorio\n",
    "from sklearn.dummy import DummyClassifier # se utilizar√° un modelo dummy para la prueba de cordura\n",
    "from sklearn.model_selection import train_test_split # herramienta de segmentaci√≥n\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error # m√©tricas para evaluar exactitud y error(en caso de tareas de regresi√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informaci√≥n Comportamiento de Usuarios Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "Descripci√≥n de los tipos de datos:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "Valores Nulos presentes en el Dataset:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "\n",
      "Filas Duplicadas en el Dataset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Abrir y examinar los datos:\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "print(f\"\\nInformaci√≥n Comportamiento de Usuarios Dataset:\")\n",
    "print(df.info())\n",
    "print(f\"\\nDescripci√≥n de los tipos de datos:\\n{df.describe()}\")\n",
    "print(f\"\\nValores Nulos presentes en el Dataset:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nFilas Duplicadas en el Dataset:\\n{df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1928 entries, 2656 to 510\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     1928 non-null   float64\n",
      " 1   minutes   1928 non-null   float64\n",
      " 2   messages  1928 non-null   float64\n",
      " 3   mb_used   1928 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 75.3 KB\n",
      "None\n",
      "2371    0\n",
      "971     1\n",
      "224     0\n",
      "2811    0\n",
      "2035    0\n",
      "Name: is_ultra, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 2699 to 1806\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 25.1 KB\n",
      "None\n",
      "1187    0\n",
      "134     1\n",
      "739     0\n",
      "2571    1\n",
      "1079    0\n",
      "Name: is_ultra, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 1415 to 1196\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 25.1 KB\n",
      "None\n",
      "3044    1\n",
      "383     0\n",
      "1470    1\n",
      "2359    0\n",
      "692     0\n",
      "Name: is_ultra, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Segmentaci√≥n de Caracter√≠sticas & Objetivo\n",
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "# Divisi√≥n de conjunto de datos en 80% entrenamiento, 20% validaci√≥n, 20% prueba\n",
    "features_main, features_test, target_main, target_test = train_test_split(features, target, test_size = 0.20, random_state = 12345) # creamos temporalmente un fragmento 'main' para luego segmentarlo nuevamente\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_main, target_main, test_size = 0.25, random_state = 12345) # 0.25*0.80 = 0.20 el tama√±o de la prueba\n",
    "\n",
    "print(features_train.info())\n",
    "print(target_train.sample(5))\n",
    "print(features_valid.info())\n",
    "print(target_valid.sample(5))\n",
    "print(features_test.info())\n",
    "print(target_test.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Muy bien realizada la divisi√≥n de los datos para evaluar correctamente los modelos. Es importante tener dividido los datos ya que no se puede evaluar el modelo sobre los mismos datos que ya vi√≥ para su entrenamiento\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1, min_samples_split2 recm=0.5112, accuracy=0.7387\n",
      "max_depth=1, min_samples_split5 recm=0.5112, accuracy=0.7387\n",
      "max_depth=1, min_samples_split10 recm=0.5112, accuracy=0.7387\n",
      "max_depth=2, min_samples_split2 recm=0.4926, accuracy=0.7574\n",
      "max_depth=2, min_samples_split5 recm=0.4926, accuracy=0.7574\n",
      "max_depth=2, min_samples_split10 recm=0.4926, accuracy=0.7574\n",
      "max_depth=3, min_samples_split2 recm=0.4846, accuracy=0.7652\n",
      "max_depth=3, min_samples_split5 recm=0.4846, accuracy=0.7652\n",
      "max_depth=3, min_samples_split10 recm=0.4846, accuracy=0.7652\n",
      "max_depth=4, min_samples_split2 recm=0.4862, accuracy=0.7636\n",
      "max_depth=4, min_samples_split5 recm=0.4862, accuracy=0.7636\n",
      "max_depth=4, min_samples_split10 recm=0.4862, accuracy=0.7636\n",
      "max_depth=5, min_samples_split2 recm=0.4910, accuracy=0.7589\n",
      "max_depth=5, min_samples_split5 recm=0.4910, accuracy=0.7589\n",
      "max_depth=5, min_samples_split10 recm=0.4910, accuracy=0.7589\n",
      "max_depth=6, min_samples_split2 recm=0.4926, accuracy=0.7574\n",
      "max_depth=6, min_samples_split5 recm=0.4910, accuracy=0.7589\n",
      "max_depth=6, min_samples_split10 recm=0.4973, accuracy=0.7527\n",
      "max_depth=7, min_samples_split2 recm=0.4749, accuracy=0.7745\n",
      "max_depth=7, min_samples_split5 recm=0.4814, accuracy=0.7683\n",
      "max_depth=7, min_samples_split10 recm=0.4814, accuracy=0.7683\n",
      "max_depth=8, min_samples_split2 recm=0.4830, accuracy=0.7667\n",
      "max_depth=8, min_samples_split5 recm=0.4846, accuracy=0.7652\n",
      "max_depth=8, min_samples_split10 recm=0.4862, accuracy=0.7636\n",
      "max_depth=9, min_samples_split2 recm=0.4878, accuracy=0.7621\n",
      "max_depth=9, min_samples_split5 recm=0.4894, accuracy=0.7605\n",
      "max_depth=9, min_samples_split10 recm=0.4926, accuracy=0.7574\n",
      "max_depth=10, min_samples_split2 recm=0.4781, accuracy=0.7714\n",
      "max_depth=10, min_samples_split5 recm=0.4781, accuracy=0.7714\n",
      "max_depth=10, min_samples_split10 recm=0.4846, accuracy=0.7652\n",
      "\n",
      "Modelo √Årbol de Decisi√≥n, exactitud: 0.7745 con :{'max_depth': 7, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Probamos ahora los modelos: √Årbol de Decisi√≥n, Bosque Aleatorio y Regresi√≥n Log√≠stica ser√°n los que utilizaremos\n",
    "acc_umbral = 0.75 # declaramos el umbral de exactitud definido por el proyecto, que buscamos superar con nuestros modelos\n",
    "best_tree_acc = 0 # declaramos la variable para la exactitud del modelo vac√≠a, aqu√≠ almacenaremos la que resulte mejor del modelo con sus mejores par√°metros\n",
    "best_tree_error = 0.5 # no es necesario declarar este valor en 0.5 ni para √©ste modelo\n",
    "best_tree_c_params = {} # creamos un diccionario vac√≠o d√≥nde almacenaremos los mejores resultados de los hiperpar√°metros para nuestro modelo\n",
    "for max_depth in range(1, 11): # asignamos al bucle los valores de 1 - 10 en profundidad del √°rbol \n",
    "    for min_samples_split in [2, 5, 10]: # a√±adimos el hiperpar√°metro min_samples_split para darle m√°s flexibilidad a los hallazgos dividiendo las muestras de observaciones en m√≠nimo 2, 5 o 10 observaciones antes del siguiente nodo\n",
    "        model_tree_c = DecisionTreeClassifier(max_depth = max_depth, random_state=12345, min_samples_split = min_samples_split) # inicializamos modelo\n",
    "        model_tree_c.fit(features_train, target_train) # entrenamos modelo\n",
    "        prediction_tree_c = model_tree_c.predict(features_valid) # ejercutamos las predicciones\n",
    "        error_tree_c = (mean_squared_error(target_valid, prediction_tree_c)**0.5) # de acuerdo a la teor√≠a del sprint, √©sta m√©trica aplica m√°s para tareas de regresi√≥n\n",
    "        acc_tree_c = accuracy_score(target_valid, prediction_tree_c) # obtenemos la exactitud\n",
    "        \n",
    "        if acc_tree_c > acc_umbral and error_tree_c < best_tree_error: # condicionamos para extraer los valores que cumplen los requisitos\n",
    "            best_tree_acc = acc_tree_c\n",
    "            best_tree_error = error_tree_c\n",
    "            best_tree_c_params = {'max_depth': max_depth, 'min_samples_split': min_samples_split} # guardamos los par√°metros que cumplen con la prueba               \n",
    "        print(f\"max_depth={max_depth}, min_samples_split{min_samples_split} recm={error_tree_c:.4f}, accuracy={acc_tree_c:.4f}\") # mostramos cada iteraci√≥n\n",
    "\n",
    "print(f\"\\nModelo √Årbol de Decisi√≥n, exactitud: {best_tree_acc:.4f} con :{best_tree_c_params}\") # Imprimimos el resultado final con el que cumpli√≥ el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1, n_estimators=10, recm=0.5187 accuracy=0.7309\n",
      "max_depth=2, n_estimators=10, recm=0.4862 accuracy=0.7636\n",
      "max_depth=3, n_estimators=10, recm=0.4781 accuracy=0.7714\n",
      "max_depth=4, n_estimators=10, recm=0.4716 accuracy=0.7776\n",
      "max_depth=5, n_estimators=10, recm=0.4716 accuracy=0.7776\n",
      "max_depth=6, n_estimators=10, recm=0.4633 accuracy=0.7854\n",
      "max_depth=7, n_estimators=10, recm=0.4616 accuracy=0.7869\n",
      "max_depth=8, n_estimators=10, recm=0.4633 accuracy=0.7854\n",
      "max_depth=9, n_estimators=10, recm=0.4531 accuracy=0.7947\n",
      "max_depth=10, n_estimators=10, recm=0.4582 accuracy=0.7900\n",
      "max_depth=1, n_estimators=20, recm=0.5172 accuracy=0.7325\n",
      "max_depth=2, n_estimators=20, recm=0.4878 accuracy=0.7621\n",
      "max_depth=3, n_estimators=20, recm=0.4781 accuracy=0.7714\n",
      "max_depth=4, n_estimators=20, recm=0.4732 accuracy=0.7760\n",
      "max_depth=5, n_estimators=20, recm=0.4699 accuracy=0.7792\n",
      "max_depth=6, n_estimators=20, recm=0.4633 accuracy=0.7854\n",
      "max_depth=7, n_estimators=20, recm=0.4633 accuracy=0.7854\n",
      "max_depth=8, n_estimators=20, recm=0.4616 accuracy=0.7869\n",
      "max_depth=9, n_estimators=20, recm=0.4565 accuracy=0.7916\n",
      "max_depth=10, n_estimators=20, recm=0.4514 accuracy=0.7963\n",
      "max_depth=1, n_estimators=30, recm=0.5112 accuracy=0.7387\n",
      "max_depth=2, n_estimators=30, recm=0.4894 accuracy=0.7605\n",
      "max_depth=3, n_estimators=30, recm=0.4798 accuracy=0.7698\n",
      "max_depth=4, n_estimators=30, recm=0.4732 accuracy=0.7760\n",
      "max_depth=5, n_estimators=30, recm=0.4699 accuracy=0.7792\n",
      "max_depth=6, n_estimators=30, recm=0.4649 accuracy=0.7838\n",
      "max_depth=7, n_estimators=30, recm=0.4633 accuracy=0.7854\n",
      "max_depth=8, n_estimators=30, recm=0.4649 accuracy=0.7838\n",
      "max_depth=9, n_estimators=30, recm=0.4565 accuracy=0.7916\n",
      "max_depth=10, n_estimators=30, recm=0.4565 accuracy=0.7916\n",
      "max_depth=1, n_estimators=40, recm=0.5112 accuracy=0.7387\n",
      "max_depth=2, n_estimators=40, recm=0.4878 accuracy=0.7621\n",
      "max_depth=3, n_estimators=40, recm=0.4781 accuracy=0.7714\n",
      "max_depth=4, n_estimators=40, recm=0.4699 accuracy=0.7792\n",
      "max_depth=5, n_estimators=40, recm=0.4683 accuracy=0.7807\n",
      "max_depth=6, n_estimators=40, recm=0.4683 accuracy=0.7807\n",
      "max_depth=7, n_estimators=40, recm=0.4649 accuracy=0.7838\n",
      "max_depth=8, n_estimators=40, recm=0.4616 accuracy=0.7869\n",
      "max_depth=9, n_estimators=40, recm=0.4582 accuracy=0.7900\n",
      "max_depth=10, n_estimators=40, recm=0.4514 accuracy=0.7963\n",
      "max_depth=1, n_estimators=50, recm=0.5035 accuracy=0.7465\n",
      "max_depth=2, n_estimators=50, recm=0.4894 accuracy=0.7605\n",
      "max_depth=3, n_estimators=50, recm=0.4830 accuracy=0.7667\n",
      "max_depth=4, n_estimators=50, recm=0.4749 accuracy=0.7745\n",
      "max_depth=5, n_estimators=50, recm=0.4699 accuracy=0.7792\n",
      "max_depth=6, n_estimators=50, recm=0.4683 accuracy=0.7807\n",
      "max_depth=7, n_estimators=50, recm=0.4616 accuracy=0.7869\n",
      "max_depth=8, n_estimators=50, recm=0.4616 accuracy=0.7869\n",
      "max_depth=9, n_estimators=50, recm=0.4599 accuracy=0.7885\n",
      "max_depth=10, n_estimators=50, recm=0.4496 accuracy=0.7978\n",
      "\n",
      "Modelo Bosque Aleatorio, exactitud: 0.7978 con {'max_depth': 10, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Repetimos los pasos que aplicamos a nuestro anterior modelo pero ahora con las caracter√≠sticas del Bosque Aleatorio:\n",
    "best_forest_acc = 0\n",
    "best_forest_error = 0.5\n",
    "best_forest_c_params = {}\n",
    "for est in range(10, 51, 10): # Esta vez establecemos el hiperpar√°metro de n√∫mero de estimadores, de 10 a 50 escalando de 10 en 10 en cada iteraci√≥n\n",
    "    for max_depth in range(1, 11):\n",
    "            model_forest_c = RandomForestClassifier(n_estimators = est, max_depth = max_depth, random_state=12345)\n",
    "            model_forest_c.fit(features_train, target_train)\n",
    "            prediction_forest_c = model_forest_c.predict(features_valid)\n",
    "            error_forest_c = (mean_squared_error(target_valid, prediction_forest_c)**0.5)\n",
    "            acc_forest_c = accuracy_score(target_valid, prediction_forest_c)\n",
    "        \n",
    "            if acc_forest_c > acc_umbral and error_forest_c < best_forest_error:\n",
    "                best_forest_acc = acc_forest_c\n",
    "                best_forest_error = error_forest_c\n",
    "                best_forest_c_params = {'max_depth': max_depth, 'n_estimators': est}\n",
    "            \n",
    "            print(f\"max_depth={max_depth}, n_estimators={est}, recm={error_forest_c:.4f} accuracy={acc_forest_c:.4f}\")\n",
    "\n",
    "print(f\"\\nModelo Bosque Aleatorio, exactitud: {best_forest_acc:.4f} con {best_forest_c_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Muy bien planteado el c√≥digo para probar con los diferentes modelos para conseguir un mejor performance!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NO CUMPLE; \n",
      "Modelo Regresi√≥n Log√≠stica, exactitud: 0.6998 error: 0.5479\n"
     ]
    }
   ],
   "source": [
    "# Ahora probaremos el modelo de Regresi√≥n Log√≠stica, para el cual solo necesitaremos usar el par√°metro solver, com√∫nmente usado para datos peque√±os\n",
    "model_logic_r = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_logic_r.fit(features_train, target_train)\n",
    "prediction_logic_r = model_logic_r.predict(features_valid)\n",
    "error_logic_r = (mean_squared_error(target_valid, prediction_logic_r)**0.5)\n",
    "acc_logic_r = accuracy_score(target_valid, prediction_logic_r)\n",
    "        \n",
    "if acc_logic_r > acc_umbral and error_logic_r < 0.5: # Le aplicamos las mismas condiciones bajo las cuales sometimos a nuestros anteriores modelos\n",
    "    print(f\"\\nModelo Regresi√≥n Log√≠stica, exactitud: {acc_logic_r:.4f} error: {error_logic_r:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nNO CUMPLE; \\nModelo Regresi√≥n Log√≠stica, exactitud: {acc_logic_r:.4f} error: {error_logic_r:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de Evaluar y entrenar cada modelo se observa que el modelo que mejor se comport√≥ durante la tarea fue el Bosque Aleatorio. Obtuvimos sus Hiperpar√°metros y ahora lo designaremos para el conjunto de prueba; sabemos que aunque el valor del error no le corresponde, s√≠ nos fijamos en la exactitud el modelo satisface la condici√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en conjunto de PRUEBA: 0.7994\n",
      "‚úÖ EXITOSO: Exactitud 0.7994 >= 0.75\n",
      "El modelo cumple con el requisito m√≠nimo de exactitud\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de prueba usando el mejor modelo; best_forest_c_params = {'max_depth': max_depth, 'n_estimators': est}\n",
    "best_model = RandomForestClassifier(random_state = 12345, max_depth = best_forest_c_params['max_depth'], n_estimators = best_forest_c_params['n_estimators'])\n",
    "best_model.fit(features_train, target_train) # entrenamos el modelo\n",
    "test_predictions = best_model.predict(features_test)\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "print(f\"Exactitud en conjunto de PRUEBA: {test_accuracy:.4f}\")\n",
    "if test_accuracy >= 0.75: # finalmente corroboramos que el conjunto de prueba supere la condici√≥n de la exactitud que buscamos con los par√°metros con los que pas√≥ el conjunto de validaci√≥n\n",
    "    print(f\"‚úÖ EXITOSO: Exactitud {test_accuracy:.4f} >= 0.75\")\n",
    "    print(\"El modelo cumple con el requisito m√≠nimo de exactitud\")\n",
    "else:\n",
    "    print(f\"‚ùå FALLIDO: Exactitud {test_accuracy:.4f} < 0.75\")\n",
    "    print(\"El modelo no cumple con el requisito m√≠nimo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo dummy por estrategia mayoritaria: 0.6952\n",
      "Exactitud de nuestro modelo: 0.7994\n",
      "‚úÖ El modelo supera la prueba de cordura\n"
     ]
    }
   ],
   "source": [
    "# Prueba de cordura; para este ejercicio eleg√≠ utilizar un modelo dummy, que nos ayudar√° a predecir la clase mayoritaria por medio de la estrategia: most_frequent\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy_accuracy = accuracy_score(target_test, dummy.predict(features_test))\n",
    "\n",
    "print(f\"Exactitud del modelo dummy por estrategia mayoritaria: {dummy_accuracy:.4f}\")\n",
    "print(f\"Exactitud de nuestro modelo: {test_accuracy:.4f}\")\n",
    "\n",
    "if test_accuracy > dummy_accuracy: # comparamos nuestro modelo con el modelo dummy para determinar si es capaz de superar la prueba de cordura\n",
    "    print(\"‚úÖ El modelo supera la prueba de cordura\")\n",
    "else:\n",
    "    print(\"‚ùå El modelo NO supera la prueba de cordura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusi√≥n Final:\n",
    "Nuestros modelos aunque se hayan entrenado e iterado sobre un rango de par√°metros arbitrario dieron un √≥ptimo resultado para la prueba; con esto nos damos cuenta de las diferencias que presentan cada uno y como nos ayudan a entrenar el mejor modelo para as√≠ obtener las predicciones m√°s exactas sin resultados enga√±osos y con la certeza de no estar sobreajustados ni subajustados.\n",
    "Comparando cada modelo determinamos que con el √Årbol de Decisi√≥n podemos f√°cilmente interpretar el comportamiento de los datos y este no requiere escalado prominente, sinembargo est√° m√°s expuesto a caer en el sobreajuste, a diferencia del bosque aleatorio que nos da m√°s precisi√≥n, menor sobreajuste y aunque sea m√°s lento da mejores resultados, en cuanto a la regresi√≥n log√≠stica, entiendo que supone una distribuci√≥n lineal, aunque no este del todo familiarizado con los t√©rminos estad√≠sticos que conlleva realizar √©stas pruebas a √©ste modelo, estoy convencido de que sus funciones no eran las m√°s √≥ptimas para este caso en particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Buen trabajo con tu proyecto! Entrenaste los modelos correctamente obteniendo una m√©trica por encima de lo propuesto.\n",
    "    \n",
    "Como recomendaciones, ser√≠a explorar m√°s los datos y la calidad de los mismos, as√≠ como redactar conclusiones m√°s detalladas de lo observado en un EDA y c√≥mo podr√≠a estar relacion√°ndose con los resultados de tus modelos.\n",
    "    \n",
    "Saludos!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
